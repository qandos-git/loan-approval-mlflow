{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split, cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this cell only once\n",
    "\n",
    "'''# Create a new experiment\n",
    "experiment_id = mlflow.create_experiment(\n",
    "        name=\"loan_approval_predictions\",\n",
    "        artifact_location=\"loan_approval_predictions_artifacts\",\n",
    "        tags={\"env\": \"dev\", \"version\": \"1.0.0\"},\n",
    "    )\n",
    "\n",
    "print(experiment_id)    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive experiment id using experiment name to reuse it\n",
    "\n",
    "experiment_id = mlflow.set_experiment(\"loan_approval_predictions\").experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "df = pd.read_csv(\"artifacts\\data\\loan_data.csv\")\n",
    "\n",
    "#Investigate data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**person_age**\tAge of the person\t\n",
    "\n",
    "**person_gender**\tGender of the person\t\n",
    "\n",
    "**person_education**\tHighest education level\t\n",
    "\n",
    "**person_income**\tAnnual income\t\n",
    "\n",
    "**person_emp_exp**\tYears of employment experience\t\n",
    "\n",
    "**person_home_ownership**\tHome ownership status (e.g., rent, own, mortgage)\t\n",
    "\n",
    "**loan_amnt**\tLoan amount requested\t\n",
    "\n",
    "**loan_intent**\tPurpose of the loan\t\n",
    "\n",
    "**loan_int_rate**\tLoan interest rate\t\n",
    "\n",
    "**loan_percent_income**\tLoan amount as a percentage of annual income\t\n",
    "\n",
    "**cb_person_cred_hist_length**\tLength of credit history in years\t\n",
    "\n",
    "**credit_score**\tCredit score of the person\t\n",
    "\n",
    "**previous_loan_defaults_on_file**\tIndicator of previous loan defaults\t\n",
    "\n",
    "**loan_status (target variable)**\tLoan approval status: 1 = approved; 0 = rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data exploration\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can see that we don't have any missing values or null values.\n",
    " \n",
    " We have to convert integers into floats, so ML algorithms process them better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are wrong values in [Person_age], the maximum value is 144! we are not dinasours, so we have to check for outliers in [Person_age] column.\n",
    "\n",
    " There are wrong values in [person_emp_exp], the maximum value is 125! so we have to check for outliers in [person_emp_exp] column.\n",
    "\n",
    " There could be outliers in [person_income], [loan_amnt], [cb_person_cred_hist_length].\n",
    "\n",
    " [loan_percent_income] repeate 2 information, [loan_amnt] and [person_income], so we can look for removing one of these to reveale correlation.\n",
    "\n",
    " we have to check for any correlation between the target variable [loan_status] and [[credit_score],[previous_loan_defaults_on_file], [loan_int_rate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Remove wrong valeus from [person_age] and [person_emp_exp] columns\n",
    "    1. show boxplot for each column to decide the border.\n",
    "    2. remove values greater than border value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_emp_exp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove wrong valeus from [person_age] and [person_emp_exp] columns\n",
    "\n",
    "df = df[(df[\"person_age\"] < 80)]\n",
    "df = df[(df[\"person_emp_exp\"] < 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_emp_exp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is right that there are still some outliers in the two columns, but these values are real information so we will keep them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second: Check outliers for [person_income], [loan_amnt], [cb_person_cred_hist_length] columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_income')\n",
    "plt.show()\n",
    "sns.boxenplot(data=df, y='loan_amnt')\n",
    "plt.show()\n",
    "sns.boxenplot(data=df, y='cb_person_cred_hist_length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to invistigate the [annual_income] more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_income', x='person_education')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=df, y='person_income', x='person_home_ownership')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,  y='person_income', x='loan_amnt')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,  y='person_income', x='loan_amnt', hue='loan_intent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[person_income] has a problem, so we have to know more about incomes in US.\n",
    "1. It's clear now that there are wrong values in the dataset, as it's unnatureal for those who get annual income of more than 1M$ to loan less than 15K$\n",
    "\n",
    "2.  Minimum income as 8000$ is definitely wrong, it could be the information of monthly income, because the average annual income in 2022 US for age +25 is more than 30,0000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['person_income'] < 15_000].index, inplace=True)\n",
    "df.drop(df[(df['person_income'] > 1_000_000) & (df['loan_amnt'] < 15_000)].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For [loan_amnt] column we will remove values less than 1000, because \"Most banks, credit unions, and online lenders don't offer personal loans for less than $1,000\" (Source)[https://www.investopedia.com/can-you-get-a-usd500-personal-loan-7852432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['loan_amnt'] < 1_000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x = 'person_age', y='cb_person_cred_hist_length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ['cb_person_cred_hist_length'], there are no problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therd: [[loan_percent_income]] repeate 2 information, [loan_amnt] and [person_income], so we can look for removing one of these to reveale correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that [loan_percent_income] and [loan_amnt] are correlated ~(0.60), but it is not highly correlated, event the negative correlation with [person_income] is not that high, making a question of the correctness data in this column and give stronger reaon to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['loan_percent_income'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth: check for any correlation between the target variable [loan_status] and [[credit_score],[previous_loan_defaults_on_file], [loan_int_rate]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation = df[['credit_score', 'previous_loan_defaults_on_file', 'loan_int_rate', 'loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "cat = ['previous_loan_defaults_on_file', 'loan_status']\n",
    "\n",
    "for col in cat:\n",
    "    data_correlation[col] = le.fit_transform(data_correlation[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_correlation.corrwith(data_correlation['loan_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[previous_loan_defaults_on_file] is correlated with the [loan_status] by -0.540675, this is consoderied as negative moderate correlation, so we can consider it as usefull information and keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='loan_status',axis=1)\n",
    "y = df['loan_status']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(\"object\").columns\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column transformer to encode categorical columns\n",
    "\n",
    "cat_transformer = ColumnTransformer([\n",
    "    ('one_hot',OneHotEncoder(drop='first', handle_unknown='ignore'),['person_gender','loan_intent']),\n",
    "    ('ordinal',OrdinalEncoder(categories=[[ \"High School\",\"Associate\",\"Bachelor\",\"Master\",\"Doctorate\"],['OTHER','MORTGAGE','RENT','OWN'],['No','Yes']],handle_unknown='error'),['person_education', 'person_home_ownership','previous_loan_defaults_on_file'])],\n",
    "    remainder='passthrough')\n",
    "\n",
    "scale_transformer = ColumnTransformer([('scaler', StandardScaler(), slice(0, None))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced training data, so we need to experiment with multiple approaches and multiple models to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'f1': 'f1',\n",
    "           'roc_auc': 'roc_auc',\n",
    "           'precision': 'precision',\n",
    "           'recall': 'recall'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I will include main changes in the run name\n",
    "run_name = \" LogisticRegression with SMOTE\"\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"CategoricalFeatures\", cat_transformer),\n",
    "    ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
    "#    ('undersampler', RandomUnderSampler(sampling_strategy='auto', random_state=42)),\n",
    "    (\"Scaler\", scale_transformer),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "scores = cross_validate(estimator=pipe,\n",
    "                        X=X_train,\n",
    "                        y=y_train,\n",
    "                        cv=10, \n",
    "                        scoring=scoring,\n",
    "                        n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_mean = scores.get('test_f1').mean()\n",
    "roc_auc_mean = scores.get('test_roc_auc').mean()\n",
    "precision_mean = scores.get('test_precision').mean()\n",
    "recall_mean = scores.get('test_recall').mean()\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name):\n",
    "    # Log parameters of the classifier in the pipeline\n",
    "    mlflow.log_params(pipe.named_steps['clf'].get_params())\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"f1_mean\", f1_mean)\n",
    "    mlflow.log_metric(\"roc_auc_mean\", roc_auc_mean)\n",
    "    mlflow.log_metric(\"precision_mean\", precision_mean)\n",
    "    mlflow.log_metric(\"recall_mean\", recall_mean)\n",
    "\n",
    "    # Log the pipeline model\n",
    "    mlflow.sklearn.log_model(pipe, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Results](artifacts/images/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see after comparing all the experiments that **RandomForestClassifier with SMOTE** gives the most robust performance, so we will test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    (\"CategoricalFeatures\", cat_transformer),\n",
    "    ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
    "    (\"Scaler\", scale_transformer),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we care about the two classes equally, this performance is very good.\n",
    "so, we will register the model and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('artifacts\\model\\model_v1.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
